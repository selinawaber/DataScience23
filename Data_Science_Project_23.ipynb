{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5eb2e6b6",
   "metadata": {},
   "source": [
    "# Data Science Project Spring 2023\n",
    "\n",
    "## 200+ Financial Indicators of US stocks (2014-2018)\n",
    "\n",
    "### Yiwei Gong, Janice Herman, Alexander  Morawietz and Selina Waber"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f1ae56",
   "metadata": {},
   "source": [
    "University of Zurich, Spring 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2b845b",
   "metadata": {},
   "source": [
    "## Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20c3eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b155f9",
   "metadata": {},
   "source": [
    "## Loading the Data Set\n",
    "\n",
    "\n",
    "We used the data set from Nicolas Carbone from the webpage [kaggle](https://www.kaggle.com/datasets/cnic92/200-financial-indicators-of-us-stocks-20142018). Each dataset contains over 200 financial indicators, that are found in the [10-K filings](https://www.investopedia.com/terms/1/10-k.asp#:~:text=Key%20Takeaways-,A%2010%2DK%20is%20a%20comprehensive%20report%20filed%20annually%20by,detailed%20than%20the%20annual%20report.) of publicly traded companies from the US between the years 2014 - 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c1f832",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_directory = sys.path[0] ## get path of project directory\n",
    "data_directory = os.path.join(project_directory, 'data')\n",
    "\n",
    "years = [2014, 2015, 2016, 2017, 2018]\n",
    "\n",
    "## Loading the yearly dataset into the array dfs\n",
    "dfs = []\n",
    "for year in years:\n",
    "    df = pd.read_csv(os.path.join(data_directory, f'{year}_Financial_Data.csv'), sep=',')\n",
    "    df['year'] = np.full(df.shape[0], str(year)) ## append column with the year respecitvely\n",
    "    df['PRICE VAR [%]'] = df[f'{year +1} PRICE VAR [%]'] ## Adding variable of the same name for all df, e.g. '2016 PRICE VAR [%]' renamed to 'PRICE VAR [%]'\n",
    "    df = df.drop(columns=[f'{year +1} PRICE VAR [%]']) # dropp year-specific variable name\n",
    "    df.columns.values[0] = 'Stock Name' # name the first variable \n",
    "    dfs.append(df)\n",
    "    \n",
    "    \n",
    "df = pd.concat(dfs) ## concat the diffrent dataframes\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890b9407",
   "metadata": {},
   "source": [
    "## Some Explanation of Variables:\n",
    "\n",
    "### Adding  `year` as a cathegorical variable\n",
    "\n",
    "We added a column named `year` which contains the respecitve year.\n",
    "\n",
    "\n",
    "\n",
    "### Handling the variable `Price VAR [%]`\n",
    "\n",
    "The last column, `PRICE VAR [%]`, lists the percent price variation of each stock for the year. For example, if we consider the dataset 2015_Financial_Data.csv, we will have:\n",
    "\n",
    "- 200+ financial indicators for the year 2015;\n",
    "- percent price variation for the year 2016 (meaning from the first trading day on Jan 2016 to the last trading day on Dec 2016).\n",
    "\n",
    "We renamed all the variables with the specific year in it, e.g.  `2016 PRICE VAR [%]` to `PRICE VAR [%]`. We dropped the old ones.Now we just have one variable `PRICE VAR [%]`. \n",
    "\n",
    "\n",
    "### The variable `class`\n",
    "\n",
    "class lists a binary classification for each stock, where\n",
    "\n",
    "- for each stock, if the PRICE VAR [%] value is positive, class = 1. From a trading perspective, the 1 identifies those stocks that an hypothetical trader should BUY at the start of the year and sell at the end of the year for a profit.\n",
    "- for each stock, if the PRICE VAR [%] value is negative, class = 0. From a trading perspective, the 0 identifies those stocks that an hypothetical trader should NOT BUY, since their value will decrease, meaning a loss of capital.\n",
    "\n",
    "\n",
    "The columns `PRICE VAR [%]` and `class` make possible to use the datasets for both classification and regression tasks:\n",
    "\n",
    "- If the user wishes to train a machine learning model so that it learns to classify those stocks that in buy-worthy and not buy-worthy, it is possible to get the targets from the class column;\n",
    "- If the user wishes to train a machine learning model so that it learns to predict the future value of a stock, it is possible to get the targets from the PRICE VAR [%] column.\n",
    "\n",
    "\n",
    "### The variable  `Stock Name`\n",
    "\n",
    "We named the first variable `Stock Name`since it has not been named in the original dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ed3e83",
   "metadata": {},
   "source": [
    "## First Description of the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b37ad7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c5f8fc",
   "metadata": {},
   "source": [
    "## Numerical and Catgorical Features/Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7252b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "numCols = list(df.select_dtypes(exclude='object').columns)\n",
    "print(f\"There are {len(numCols)} numerical features:\\n\")\n",
    "\n",
    "catCols = list(df.select_dtypes(include='object').columns)\n",
    "print(f\"There are {len(catCols)} categorical features:\\n\", catCols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872e4dda",
   "metadata": {},
   "source": [
    "## Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6239f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().mean().sort_values(ascending=False).plot.bar(figsize=(60,20))\n",
    "plt.ylabel('Percentage of missing values')\n",
    "plt.xlabel('Variables')\n",
    "plt.title('Quantifying missing data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c8f4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of missing values for the variables\n",
    "\n",
    "# Plot missing values\n",
    "missing = df.isnull().sum().sort_values(ascending=False)\n",
    "missing = missing[missing > 0]\n",
    "percent = (df.isnull().sum()/df.isnull().count()).sort_values(ascending=False)\n",
    "missing_data = pd.concat([missing, percent], axis=1, keys=['Nr. of missing values', 'Share'])\n",
    "missing_data.head(22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5790db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot missing values 2.0\n",
    "sns.heatmap(df_nan.isna().transpose(),\n",
    "            cmap=\"Blues\",\n",
    "            cbar_kws={'label': 'Missing Values'});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365cd61e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "007bd9f9",
   "metadata": {},
   "source": [
    "## Outliers cleaning\n",
    "\n",
    "There are outliers/extreme values that are probably caused by mistypings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0199c3f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3b8607",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
